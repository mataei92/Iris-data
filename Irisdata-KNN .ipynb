{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3473c4b0",
   "metadata": {},
   "source": [
    "In this project the Iris dataset (https://archive.ics.uci.edu/ml/datasets/Iris/) is used to build and train a k-nearest-neighbor (kNN) classifier using the provided knnClassify python class for different number of K values and recommend the best value of the K for training the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5ff857",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries and tools\n",
    "import numpy as np\n",
    "np.random.seed(0) # set the random number seed\n",
    "import mltools as ml\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5baddf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = np.genfromtxt(\"iris.txt\",delimiter=None) # load the text file\n",
    "Y = iris[:,-1] # target value (iris species) is the last column\n",
    "X = iris[:,0:-1] # features are the other columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd238bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data dimension info\n",
    "m, n = X.shape\n",
    "print('Number of features:', n)\n",
    "print('Number of data points:', m)\n",
    "#Plot feature histograms\n",
    "fig, ax = plt.subplots(1, 4, figsize=(20, 3))\n",
    "for i in range(n):\n",
    "  ax[i].hist(X[:,i], bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e12fc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#looking at feature statistics\n",
    "print('Mean:'); print(np.mean(X,axis=0))\n",
    "print('Variance:'); print(np.var(X,axis=0))\n",
    "print('Standard Deviation:'); print(np.std(X,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a74d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using k-Nearest-Neighbor for Predictions\n",
    "X,Y = ml.shuffleData(X,Y); # shuffle data randomly\n",
    "Xtr,Xva,Ytr,Yva = ml.splitData(X,Y, 0.75); # split data into 75/25 train/validation\n",
    "\n",
    "#Visualizing the classification boundry for k=1,5,10 and 50 and compute error rates; \n",
    "#using only the first two features, for visualization purposes\n",
    "fig,ax = plt.subplots(1, 4, figsize=(15, 3.5))\n",
    "for i,k in enumerate([1, 5, 10, 50]):\n",
    "knn = ml.knn.knnClassify()\n",
    "knn.train(Xtr[:, :2],Ytr, K=k)\n",
    "print(knn.K,knn.err(Xtr[:,0:2],Ytr),knn.err(Xva[:,0:2],Yva))\n",
    "ml.plotClassify2D(knn, Xtr[:,0:2],Ytr, axis=ax[i])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbe734d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate and plot trining and validation error rtes for more values of K \n",
    "#using only the first two features\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 5))\n",
    "K=[1,2,5,10,50,100,200];\n",
    "errTrain = [None]*len(K) # (preallocate storage for training error) \n",
    "errVa = [None]*len(K) # (preallocate storage for Validation error)\n",
    "for i,k in enumerate(K):\n",
    "    learner= ml.knn.knnClassify(Xtr[:,0:2], Ytr, K) \n",
    "    learner.train(Xtr[:,0:2], Ytr, k) #train the model\n",
    "    errTrain[i]=knn.err(Xtr[:, :2],Ytr)\n",
    "    errVa[i]=knn.err(Xva[:, :2],Yva)\n",
    "\n",
    "ax.semilogx(K, errTrain, 'r-', lw=3, label='Training')\n",
    "ax.semilogx(K, errVa, 'g-', lw=3, label='Validation')\n",
    "ax.legend()\n",
    "ax.set_xlim(9e-1, 250)\n",
    "ax.set_ylim(0, 1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c7ccaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding the optimized value of K using all features\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 5))\n",
    "K=[1,2,5,10,50,100,200];\n",
    "errTrain = [None]*len(K) # (preallocate storage for training error) \n",
    "errVa = [None]*len(K) # (preallocate storage for Validation error)\n",
    "for i,k in enumerate(K):\n",
    "    learner= ml.knn.knnClassify(Xtr, Ytr, K) \n",
    "    learner.train(Xtr, Ytr, k) #train model\n",
    "    errTrain[i]=knn.err(Xtr[:, :2],Ytr)\n",
    "    errVa[i]=knn.err(Xva[:, :2],Yva)\n",
    "    \n",
    "ax.semilogx(K, errTrain, 'r-', lw=3, label='Training')\n",
    "ax.semilogx(K, errVa, 'g-', lw=3, label='Validation')\n",
    "ax.legend()\n",
    "ax.set_xlim(9e-1, 250)\n",
    "ax.set_ylim(0, 1)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
